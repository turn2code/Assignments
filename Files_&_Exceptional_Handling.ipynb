{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\n",
        "multiprocessing is a better choice\n",
        "Ans.In Python, both multithreading and multiprocessing are ways to achieve concurrency, but they have different strengths and weaknesses depending on the task. Here are scenarios where each is preferable:\n",
        "\n",
        "When Multithreading is Preferable\n",
        "Multithreading is typically a better choice in Python when tasks are I/O-bound (waiting on external resources like files or network), due to the Global Interpreter Lock (GIL), which limits the execution of multiple threads on CPU-bound tasks. Multithreading allows for tasks to be interleaved and can be highly efficient when the CPU is often idle, waiting for I/O operations to complete.\n",
        "\n",
        "Network I/O Tasks: Examples include web scraping, making HTTP requests, or downloading files. Threads can be swapped out when they wait for responses, making it ideal for handling many network calls.\n",
        "Disk I/O Tasks: Reading and writing to files, especially when handling large data files. Threads can help manage the time spent waiting for file access, allowing other tasks to run concurrently.\n",
        "GUI Applications: In applications with a graphical user interface (e.g., Tkinter, PyQt), threading is helpful to avoid blocking the main UI thread, making the interface more responsive while other processes run in the background.\n",
        "Real-Time Data Feeds: Multithreading can handle data feeds where incoming data needs to be processed with minimal delay, like in stock market apps or sensor data monitoring.\n",
        "When Memory Usage Needs to Be Minimized: Threads share the same memory space, so if the task is memory-sensitive, multithreading can help by not duplicating memory across multiple processes.\n",
        "When Multiprocessing is Preferable\n",
        "Multiprocessing is often the better choice for CPU-bound tasks that require significant computational power and need to bypass Python's GIL. Multiprocessing can leverage multiple cores, effectively distributing the workload across CPUs and boosting performance for these tasks.\n",
        "\n",
        "Heavy Computation (CPU-Bound Tasks): Tasks like mathematical calculations, data analysis, or machine learning model training. Each process can operate independently without being constrained by the GIL.\n",
        "Parallel Processing of Independent Data Sets: For tasks that involve processing chunks of data independently, like processing images or performing batch operations on datasets, multiprocessing can help speed up the operation by spreading the work across cores.\n",
        "Data Science and Machine Learning: Training models or performing large matrix calculations can benefit from multiprocessing, as each model training or data chunk can run in its own process.\n",
        "Isolation for Fault Tolerance: In cases where different tasks should run in isolated environments (e.g., handling errors or resource leaks), multiprocessing provides separate memory spaces, reducing the risk of one process affecting another.\n",
        "CPU-Intensive Simulations: For simulations (like Monte Carlo or physics simulations) that need heavy computation, multiprocessing is more effective because it can utilize the full power of the CPU cores."
      ],
      "metadata": {
        "id": "2TSYrJWNg7Zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
        "Ans.A process pool is a programming construct used to manage a group of worker processes that can execute tasks concurrently. It provides a way to create a fixed number of processes that are reused for different tasks, helping to manage system resources efficiently and reduce the overhead associated with creating and destroying processes frequently.\n",
        "\n",
        "In Python, the multiprocessing module provides a Process Pool through multiprocessing.Pool, which simplifies the task of parallelizing code and managing processes. Here’s how it works and why it’s useful:\n",
        "\n",
        "How a Process Pool Works\n",
        "Pre-created Processes: The pool is initialized with a fixed number of worker processes, often set to match the number of available CPU cores.\n",
        "Task Queue: When a new task is submitted to the pool, it’s placed in a queue, and one of the available worker processes picks up the task for execution. This approach ensures efficient task distribution across processes.\n",
        "Reusability of Processes: After a worker process completes a task, it becomes available to take on a new task from the queue, avoiding the overhead of creating and destroying processes for each task.\n",
        "Automatic Load Balancing: The process pool helps balance the load across processes by dynamically assigning tasks to the next available worker, which is especially useful when tasks vary in duration or complexity.\n",
        "Benefits of Using a Process Pool\n",
        "Resource Efficiency: By reusing a fixed number of processes, the pool limits memory and CPU consumption, preventing the system from becoming overwhelmed by too many processes.\n",
        "Reduced Overhead: Process creation and teardown are expensive operations. By reusing processes, a pool significantly reduces the time and computational cost associated with starting and stopping processes frequently.\n",
        "Simplified Parallelism: The pool abstracts away much of the complexity of managing multiple processes. Users only need to specify tasks, and the pool handles process assignment, making it easier to implement concurrency.\n",
        "Automatic Scaling: The pool size can be adjusted to the number of CPU cores or based on the workload, allowing optimized performance without manual management."
      ],
      "metadata": {
        "id": "Facr05eehsWq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSFVIM61gvil"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "# Create a process pool with 4 processes\n",
        "with Pool(4) as pool:\n",
        "    # Map the 'square' function to a list of numbers, parallelizing the computation\n",
        "    results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3.Explain what multiprocessing is and why it is used in Python programs\n",
        "Ans.Multiprocessing is a programming technique used to execute multiple processes concurrently by taking advantage of multiple CPU cores. Unlike multithreading, where multiple threads share the same memory space, multiprocessing runs separate processes, each with its own memory space. This makes it especially suitable for CPU-bound tasks, as each process can run independently on different CPU cores, maximizing the computational power available on a multi-core system.\n",
        "\n",
        "Why Multiprocessing is Used in Python\n",
        "Python’s Global Interpreter Lock (GIL) restricts multiple native threads from executing Python bytecode in parallel within the same process. This lock is intended to ensure memory management consistency, but it limits the use of true parallelism in multithreading. For CPU-intensive tasks, where significant computation is required, Python threads end up being ineffective at improving performance due to this GIL constraint.\n",
        "\n",
        "Multiprocessing, however, overcomes this limitation by creating separate processes—each with its own interpreter and memory space—allowing multiple Python processes to run simultaneously on different CPU cores. This parallelism can lead to a substantial improvement in performance for CPU-bound tasks.\n",
        "\n",
        "Advantages of Using Multiprocessing\n",
        "True Parallelism: Since each process has its own memory space and interpreter, multiple processes can execute Python code simultaneously, using multiple cores to achieve true parallelism.\n",
        "Bypasses the GIL: Multiprocessing allows for full utilization of the CPU, bypassing the limitations imposed by the GIL on multithreading.\n",
        "Scalability: With multiprocessing, tasks can be split into multiple independent processes that can be distributed across multiple CPU cores, providing scalability for tasks that require significant computational resources.\n",
        "Isolation: Each process runs independently, which isolates memory and state changes. This makes multiprocessing ideal for fault-tolerant designs, as issues in one process do not affect others.\n",
        "Common Use Cases for Multiprocessing\n",
        "CPU-Bound Computations: Tasks that require a large amount of computation, such as mathematical calculations, data processing, or image processing, benefit from multiprocessing as they can fully utilize CPU cores.\n",
        "Parallel Data Processing: Handling large datasets by processing chunks of data in parallel, as in data analytics or machine learning model training.\n",
        "Batch Processing: For tasks like batch image or video processing, multiprocessing can speed up the workflow by distributing tasks across multiple processes.\n",
        "Scientific Simulations: Tasks that require running multiple simulations, like Monte Carlo simulations or complex modeling, can take advantage of multiprocessing to perform multiple simulations simultaneously."
      ],
      "metadata": {
        "id": "t-x1wQTRg2C_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process\n",
        "\n",
        "def square(num):\n",
        "    print(f\"The square of {num} is {num * num}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Creating multiple processes\n",
        "    processes = [Process(target=square, args=(i,)) for i in range(5)]\n",
        "\n",
        "    # Start each process\n",
        "    for process in processes:\n",
        "        process.start()\n",
        "\n",
        "    # Wait for all processes to finish\n",
        "    for process in processes:\n",
        "        process.join()\n"
      ],
      "metadata": {
        "id": "xIzkBSRXiSCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4.Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
        "thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
        "threading.Lock.\n",
        "Ans.To create a Python program using multithreading where one thread adds numbers to a list and another thread removes numbers, we need to synchronize access to the list to avoid race conditions. This can be achieved using threading.Lock, which ensures that only one thread accesses the shared resource (the list) at any given time.\n",
        "\n",
        "Here's the Python program implementing this:"
      ],
      "metadata": {
        "id": "iUAqSc7Bgz0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared list\n",
        "numbers = []\n",
        "# Lock for synchronizing access to the list\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function for the producer thread to add numbers to the list\n",
        "def add_numbers():\n",
        "    for i in range(10):\n",
        "        with lock:  # Acquire the lock before modifying the list\n",
        "            num = random.randint(1, 100)\n",
        "            numbers.append(num)\n",
        "            print(f\"Added {num} to the list.\")\n",
        "        time.sleep(0.1)  # Simulate some delay\n",
        "\n",
        "# Function for the consumer thread to remove numbers from the list\n",
        "def remove_numbers():\n",
        "    for i in range(10):\n",
        "        with lock:  # Acquire the lock before modifying the list\n",
        "            if numbers:  # Check if the list is not empty\n",
        "                removed_num = numbers.pop(0)\n",
        "                print(f\"Removed {removed_num} from the list.\")\n",
        "            else:\n",
        "                print(\"List is empty, waiting for numbers.\")\n",
        "        time.sleep(0.15)  # Simulate some delay\n",
        "\n",
        "# Create threads for adding and removing numbers\n",
        "producer_thread = threading.Thread(target=add_numbers)\n",
        "consumer_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start the threads\n",
        "producer_thread.start()\n",
        "consumer_thread.start()\n",
        "\n",
        "# Wait for both threads to complete\n",
        "producer_thread.join()\n",
        "consumer_thread.join()\n",
        "\n",
        "print(\"Final list:\", numbers)\n"
      ],
      "metadata": {
        "id": "fBhbDzM2imRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How Lock Prevents Race Conditions\n",
        "By using lock with the with statement (which automatically acquires and releases the lock), we ensure that only one thread can modify the numbers list at any time. This prevents race conditions, ensuring data consistency."
      ],
      "metadata": {
        "id": "EVM4zCG9iuUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5.Describe the methods and tools available in Python for safely sharing data between threads and\n",
        "processes.\n",
        "Ans.Python provides several methods and tools for safely sharing data between threads and processes, each tailored to different concurrency needs. These tools help ensure data consistency, prevent race conditions, and facilitate smooth communication across threads or processes.\n",
        "\n",
        "Tools for Data Sharing Between Threads\n",
        "threading.Lock:\n",
        "\n",
        "A Lock is a synchronization primitive that ensures that only one thread can access a shared resource at a time.\n",
        "Threads must acquire the lock before accessing the shared data and release it afterward. This prevents simultaneous access, reducing race conditions.\n"
      ],
      "metadata": {
        "id": "qyA0-WTEivq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lock = threading.Lock()\n",
        "with lock:\n",
        "    # safely access shared data\n"
      ],
      "metadata": {
        "id": "SFPQB4q9i7WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "threading.RLock (Reentrant Lock):\n",
        "\n",
        "An RLock (Reentrant Lock) allows the same thread to acquire the lock multiple times without causing a deadlock.\n",
        "Useful when a thread needs to enter multiple critical sections that require the same lock.\n"
      ],
      "metadata": {
        "id": "MEGOX6lMjwkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rlock = threading.RLock()\n",
        "with rlock:\n",
        "    # safely access shared data\n"
      ],
      "metadata": {
        "id": "HuRZyVlYjxQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "threading.Semaphore:\n",
        "\n",
        "A Semaphore controls access to a resource with a specified maximum number of allowed concurrent accesses.\n",
        "Useful when managing a limited number of resources, like database connections or API requests.\n"
      ],
      "metadata": {
        "id": "RzmOXdxPjzNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semaphore = threading.Semaphore(3)  # max 3 threads can access at once\n",
        "with semaphore:\n",
        "    # access shared resource\n"
      ],
      "metadata": {
        "id": "dszNceyXj3sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "threading.Event:\n",
        "\n",
        "An Event allows threads to communicate by signaling each other.\n",
        "One thread can set an event, and other threads can wait for the event to be set before proceeding.\n",
        "Useful for coordinating start, stop, or specific actions across threads.\n"
      ],
      "metadata": {
        "id": "cEe510qDj5qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event = threading.Event()\n",
        "event.wait()  # wait until event is set by another thread\n"
      ],
      "metadata": {
        "id": "fLf8b8F1j8UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "queue.Queue:\n",
        "\n",
        "queue.Queue is a thread-safe data structure that can be used to share data between threads safely.\n",
        "Provides methods like put() and get() to add and retrieve data, ensuring data is safely shared without additional locking.\n"
      ],
      "metadata": {
        "id": "aiiScnGEj-KC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from queue import Queue\n",
        "q = Queue()\n",
        "q.put(data)\n",
        "data = q.get()\n"
      ],
      "metadata": {
        "id": "ZkEsKEWwkBDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tools for Data Sharing Between Processes\n",
        "multiprocessing.Queue:\n",
        "\n",
        "A multiprocessing.Queue provides a FIFO queue that can safely be shared between processes.\n",
        "Acts as a pipe for inter-process communication, allowing one process to put data into the queue and another to retrieve it.\n"
      ],
      "metadata": {
        "id": "LWyf9eNWkDOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Queue\n",
        "q = Queue()\n",
        "q.put(data)\n",
        "data = q.get()\n"
      ],
      "metadata": {
        "id": "DIa_aEO_kRY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiprocessing.Manager:\n",
        "\n",
        "A Manager object provides a way to create shared data structures (like lists, dictionaries) across processes.\n",
        "These shared structures are proxies managed by the manager process, ensuring safe concurrent access.\n"
      ],
      "metadata": {
        "id": "z8mESv0NkTZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Manager\n",
        "manager = Manager()\n",
        "shared_list = manager.list()\n",
        "shared_list.append(data)\n"
      ],
      "metadata": {
        "id": "H6jN4jNpkV6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiprocessing.Value and multiprocessing.Array:\n",
        "\n",
        "Value and Array are used to share simple data types and arrays between processes.\n",
        "They are stored in shared memory and can be synchronized with locks to ensure safe access.\n"
      ],
      "metadata": {
        "id": "WVteyfXDkYFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Value, Array\n",
        "shared_value = Value('i', 0)  # integer value, initialized to 0\n",
        "shared_array = Array('i', [1, 2, 3])\n"
      ],
      "metadata": {
        "id": "2sz_ge0Qkavk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiprocessing.Pipe:\n",
        "\n",
        "A Pipe provides a direct communication channel between two processes.\n",
        "Two ends of a pipe allow one process to send data and the other to receive, making it suitable for two-way communication.\n"
      ],
      "metadata": {
        "id": "BO9kYPu5kcnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pipe\n",
        "parent_conn, child_conn = Pipe()\n",
        "parent_conn.send(data)\n",
        "data = child_conn.recv()\n"
      ],
      "metadata": {
        "id": "BgIF7_Zbke6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiprocessing.Lock and multiprocessing.RLock:\n",
        "\n",
        "multiprocessing.Lock provides mutual exclusion between processes, similar to threading.Lock, ensuring only one process can access shared data at a time.\n",
        "Useful when sharing shared memory data structures, like Value and Array, to prevent race conditions.\n"
      ],
      "metadata": {
        "id": "ff8g08AmkhBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Lock\n",
        "lock = Lock()\n",
        "with lock:\n",
        "    # safely access shared resource\n"
      ],
      "metadata": {
        "id": "68OHmeVykjnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiprocessing.Semaphore:\n",
        "\n",
        "A Semaphore in multiprocessing controls access to resources, allowing a specific number of processes to access a resource concurrently.\n",
        "Useful in scenarios where limited access to shared resources is required.\n"
      ],
      "metadata": {
        "id": "YVNk-gQfklgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Semaphore\n",
        "semaphore = Semaphore(3)\n",
        "with semaphore:\n",
        "    # safely access shared resource\n"
      ],
      "metadata": {
        "id": "EktVqxJjknth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6.Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for\n",
        "doing so.\n",
        "Ans.Handling exceptions in concurrent programs is crucial because concurrency introduces complexity that can make programs more vulnerable to errors. In a concurrent environment, unhandled exceptions can lead to inconsistent states, resource leaks, deadlocks, or crashes in threads or processes. Since these issues are harder to detect and debug due to the non-deterministic nature of concurrency, robust exception handling is essential for creating reliable, maintainable programs.\n",
        "\n",
        "Here are key reasons why handling exceptions is vital in concurrent programs, followed by techniques for managing exceptions effectively.\n",
        "\n",
        "Why Exception Handling is Important in Concurrent Programs\n",
        "Data Integrity: In concurrent programs, shared resources (like data structures, files, or network connections) can be left in an inconsistent state if an exception occurs during their modification. Proper exception handling ensures resources are cleaned up correctly, preserving data integrity.\n",
        "\n",
        "Resource Management: Unhandled exceptions can leave resources such as file handles, database connections, or locks unreleased, causing resource leaks or deadlocks. This can degrade system performance or cause application crashes over time.\n",
        "\n",
        "Deadlock Prevention: In concurrent systems, exceptions can interrupt the release of locks or other synchronization primitives, leading to deadlocks if these resources are not properly managed.\n",
        "\n",
        "Error Isolation and Debugging: Exception handling helps to isolate faults within individual threads or processes, enabling easier identification and logging of errors without impacting the entire program.\n",
        "\n",
        "Graceful Shutdown and Recovery: Without proper handling, exceptions in one thread or process may propagate and cause unexpected behavior in other threads or processes. Handling exceptions gracefully allows the program to recover, restart, or shut down cleanly.\n",
        "\n",
        "Techniques for Handling Exceptions in Concurrent Programs\n",
        "1. Try-Except Blocks within Threads and Processes\n",
        "Wrapping code in try-except blocks at critical points within threads or processes helps handle exceptions locally, preventing them from propagating unexpectedly.\n",
        "Example:"
      ],
      "metadata": {
        "id": "RHPRWftXkp4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def task():\n",
        "    try:\n",
        "        # Perform task operations\n",
        "    except Exception as e:\n",
        "        print(f\"Exception in thread: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=task)\n",
        "thread.start()\n"
      ],
      "metadata": {
        "id": "EZgynvfRk7td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ". Using concurrent.futures with Exception Handling\n",
        "The concurrent.futures module provides a high-level API for managing threads and processes and has built-in support for exception handling.\n",
        "When using ThreadPoolExecutor or ProcessPoolExecutor, exceptions raised by tasks can be caught when calling result() on a Future object.\n"
      ],
      "metadata": {
        "id": "yY8g0knIlG9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def task(n):\n",
        "    if n < 0:\n",
        "        raise ValueError(\"Negative number error\")\n",
        "    return n * n\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "    future = executor.submit(task, -1)\n",
        "    try:\n",
        "        result = future.result()\n",
        "    except Exception as e:\n",
        "        print(f\"Caught exception: {e}\")\n"
      ],
      "metadata": {
        "id": "TViZ3wfNlHu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thread and Process Exception Propagation Using Callbacks\n",
        "Callbacks can be used to handle exceptions when using pools or executors.\n",
        "For example, when using concurrent.futures, a done_callback can be attached to each Future, allowing exception handling when tasks complete or fail.\n"
      ],
      "metadata": {
        "id": "LKu6SYeMlJxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def handle_result(future):\n",
        "    try:\n",
        "        result = future.result()\n",
        "        print(f\"Result: {result}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Caught exception in callback: {e}\")\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future = executor.submit(task, -1)\n",
        "    future.add_done_callback(handle_result)\n"
      ],
      "metadata": {
        "id": "yB65xbzUlMHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Exception Handling with Queues\n",
        "For producer-consumer patterns, a Queue can be used to pass exceptions back to the main thread or handling thread.\n",
        "The worker thread places exceptions on a Queue, allowing a main controller or monitor thread to handle them.\n"
      ],
      "metadata": {
        "id": "B5oNV6QclQOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import queue\n",
        "\n",
        "exception_queue = queue.Queue()\n",
        "\n",
        "def worker():\n",
        "    try:\n",
        "        # perform work\n",
        "        raise ValueError(\"Example exception\")\n",
        "    except Exception as e:\n",
        "        exception_queue.put(e)\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n",
        "thread.join()\n",
        "\n",
        "# Handle exceptions after thread completes\n",
        "while not exception_queue.empty():\n",
        "    print(f\"Exception: {exception_queue.get()}\")\n"
      ],
      "metadata": {
        "id": "Vt-B2pUElQ8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Context Managers for Resource Management\n",
        "Context managers ensure that resources are properly acquired and released, even if an exception occurs within a thread or process.\n",
        "Using with statements (e.g., with files or network connections) guarantees that resources are cleaned up in case of exceptions.\n"
      ],
      "metadata": {
        "id": "dEmvbFHelTKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Lock\n",
        "\n",
        "lock = Lock()\n",
        "\n",
        "def critical_section():\n",
        "    with lock:\n",
        "        # code here is protected, and lock will be released even if exception occurs\n"
      ],
      "metadata": {
        "id": "3XJOQQfalWjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graceful Shutdown with finally Blocks\n",
        "Using finally blocks allows for cleanup actions to be executed regardless of whether an exception occurred, which is essential for releasing locks or other shared resources.\n",
        "This technique is helpful to ensure that locks or other critical resources are always released, preventing deadlocks.\n"
      ],
      "metadata": {
        "id": "w4eSy3ZklZUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lock.acquire()\n",
        "try:\n",
        "    # critical section code\n",
        "except Exception as e:\n",
        "    print(f\"Error occurred: {e}\")\n",
        "finally:\n",
        "    lock.release()  # ensures lock is always released\n"
      ],
      "metadata": {
        "id": "3bbcGK9hldU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7 Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\n",
        "Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
        "Ans.Here's a Python program that uses concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently. Each factorial calculation is handled by a separate thread from the thread pool."
      ],
      "metadata": {
        "id": "FxytZ2I_lnWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import math\n",
        "\n",
        "# Function to calculate factorial of a number\n",
        "def factorial(n):\n",
        "    print(f\"Calculating factorial of {n}\")\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Main code\n",
        "if __name__ == \"__main__\":\n",
        "    numbers = range(1, 11)  # Numbers from 1 to 10\n",
        "\n",
        "    # Create a ThreadPoolExecutor with a number of threads equal to the number of tasks\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        # Submit tasks to the executor for each number\n",
        "        futures = {executor.submit(factorial, num): num for num in numbers}\n",
        "\n",
        "        # Process results as they complete\n",
        "        for future in futures:\n",
        "            number = futures[future]\n",
        "            try:\n",
        "                result = future.result()\n",
        "                print(f\"Factorial of {number} is {result}\")\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred while calculating factorial of {number}: {e}\")\n"
      ],
      "metadata": {
        "id": "AHE7Eke5luTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8.Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
        "parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "processes).\n",
        "Ans.Here's a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. The program measures the time taken to perform this computation using pools of different sizes (e.g., 2, 4, 8 processes) and displays the results."
      ],
      "metadata": {
        "id": "BgZJRzmYl3jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to measure time taken for parallel computation with a given pool size\n",
        "def compute_with_pool_size(pool_size, numbers):\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        start_time = time.time()  # Start time measurement\n",
        "        results = pool.map(square, numbers)  # Perform computation in parallel\n",
        "        end_time = time.time()  # End time measurement\n",
        "    duration = end_time - start_time\n",
        "    return results, duration\n",
        "\n",
        "# Main code\n",
        "if __name__ == \"__main__\":\n",
        "    numbers = list(range(1, 11))  # Numbers from 1 to 10\n",
        "\n",
        "    # Test different pool sizes\n",
        "    pool_sizes = [2, 4, 8]\n",
        "    for pool_size in pool_sizes:\n",
        "        results, duration = compute_with_pool_size(pool_size, numbers)\n",
        "        print(f\"Pool size: {pool_size}\")\n",
        "        print(f\"Results: {results}\")\n",
        "        print(f\"Time taken: {duration:.4f} seconds\\n\")\n"
      ],
      "metadata": {
        "id": "0Plz4DMDmGC3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}